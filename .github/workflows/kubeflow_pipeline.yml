name: Kubeflow Pipeline Automation

on:
  push:
    branches:
      - main

jobs:
  run-pipeline:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.7

      - name: Install dependencies
        run: |
          pip install kfp==1.8.10  # Use the appropriate version of kfp
          pip install pandas==1.2.4
          pip install numpy==1.21.0
          pip install scikit-learn==0.24.2

      - name: Compile pipeline
        run: |
          python -c "
import kfp
import kfp.dsl as dsl
from pipeline_definition import iris_classifier_pipeline  # Ensure pipeline_definition.py is in your repo

# Compile the pipeline
kfp.compiler.Compiler().compile(
    pipeline_func=iris_classifier_pipeline,
    package_path='IRIS_Classifier_pipeline2.yaml'
)"
        # Make sure you have the pipeline definition file in your repo or adjust the import accordingly.

      - name: Run pipeline
        env:
          KFP_HOST: ${{ secrets.KFP_HOST }}
          KFP_NAMESPACE: ${{ secrets.KFP_NAMESPACE }}
       
        run: |
          python -c "
import kfp
import datetime
from pipeline_definition import iris_classifier_pipeline  # Ensure pipeline_definition.py is in your repo

# Initialize KFP client
client = kfp.Client(
    host='$KFP_HOST',
    namespace='$KFP_NAMESPACE'
    # If needed, add authentication details here
)

# Define parameters
data_path = '/data'
experiment_name = 'iris_classifier_exper_' + str(datetime.datetime.now().date())
run_name = 'iris_classifier_pipeline_run'

# Submit pipeline
run_result = client.create_run_from_pipeline_func(
    iris_classifier_pipeline,
    experiment_name=experiment_name,
    run_name=run_name,
    arguments={'data_path': data_path}
)

print('Run ID:', run_result.run_id)
print('Run URL:', run_result.run_url)
"
